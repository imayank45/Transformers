{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Filtering"
      ],
      "metadata": {
        "id": "ZsnrZpJ0C9rw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "XghbJpFfAWvv"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data quality filtering\n",
        "\n",
        "# defiine a function to clean a text\n",
        "def clean_text(text):\n",
        "\n",
        "  # remove special characters, numbers and extra spaces\n",
        "  clean_text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "  cleaned_text = clean_text.lower().strip()\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "FZ5x7U8aAaTJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example data\n",
        "texts = [\n",
        "    \"!!!$$%%&&****\",\n",
        "    \"This is a useful article on AI\",\n",
        "    \"AI is the future!!\"\n",
        "]"
      ],
      "metadata": {
        "id": "3FHbJ4CGBt6D"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter data\n",
        "print([clean_text(text) for text in texts])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQQK0cKrCEvI",
        "outputId": "f9952b7b-27f1-4d17-da68-cfe664d099bb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'this is a useful article on ai', 'ai is the future']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "SIlZBPiIDCmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXZL0zLCV8s",
        "outputId": "e4bfa744-9847-423c-daae-665034ca7792"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example sentence\n",
        "sentence = \"This is a useful article on AI\""
      ],
      "metadata": {
        "id": "iabosKFfDN46"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6T8kUVDRQG",
        "outputId": "7fe45c3c-f4d8-42e5-d213-89c17c82f457"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'useful', 'article', 'on', 'AI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Sampling of Tokens"
      ],
      "metadata": {
        "id": "hKtfsoAQECue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "w7bog_pbDTyW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example dataset with 1 million tokens\n",
        "total_tokens = [\"token_\" + str(i) for i in range(1, 1000001)]\n",
        "\n",
        "# select only 1% of tokens (`0,000 tokens)\n",
        "sample_size = int(0.01 * len(total_tokens))\n",
        "reduced_tokens = random.sample(total_tokens, sample_size)"
      ],
      "metadata": {
        "id": "z55LPqM5EJGV"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total tokens: {len(total_tokens)}\")\n",
        "print(f\"Reduced tokens: {len(reduced_tokens)}\")\n",
        "print(f\"Reduced tokens: {reduced_tokens[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAHvglAtExMD",
        "outputId": "c7f5ccee-2a7e-47e9-a27b-6a3f91214d4c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 1000000\n",
            "Reduced tokens: 10000\n",
            "Reduced tokens: ['token_501001', 'token_248913', 'token_651173', 'token_264517', 'token_823195', 'token_685837', 'token_484482', 'token_648052', 'token_743765', 'token_520131']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stratified Sampling of tokens"
      ],
      "metadata": {
        "id": "Nt3mXB-bFlgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NtL4WHf_E2rA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example dataset\n",
        "token_data = [\"apple\", \"banana\", \"banana\", \"cherry\", \"cherry\", \"cherry\", \"date\", \"date\", \"date\",\"date\"]\n",
        "\n",
        "token_counts = Counter(token_data)\n",
        "print(token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l1AEBu0FuL6",
        "outputId": "ecee362f-9d01-45b7-92d4-aff5fecaa925"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'date': 4, 'cherry': 3, 'banana': 2, 'apple': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define eprcentage to keep (50% of each type)\n",
        "percentage_to_keep = 0.5"
      ],
      "metadata": {
        "id": "1_8qG6nLGAuE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform stratified sampling\n",
        "reduced_data = []\n",
        "\n",
        "for token, count in token_counts.items():\n",
        "  sample_size = max(1, int(percentage_to_keep * count))\n",
        "\n",
        "  # ensure atleast 1 token is sampled\n",
        "  reduced_data.extend([token] * sample_size)"
      ],
      "metadata": {
        "id": "DHYKO2DlGLew"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Tokens: \", token_data)\n",
        "print(\"Reduced Tokens: \", reduced_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt6q0oYVGw5K",
        "outputId": "f3a9c1fc-68bc-4a12-f192-e3b8eae13641"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens:  ['apple', 'banana', 'banana', 'cherry', 'cherry', 'cherry', 'date', 'date', 'date', 'date']\n",
            "Reduced Tokens:  ['apple', 'banana', 'cherry', 'date', 'date']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing Data Using TF-IDF scores"
      ],
      "metadata": {
        "id": "B6jPzSFtHVwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "uu6mbqvsG_5n"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample text\n",
        "corpus = [\n",
        "    \"Machine learning is amazing\",\n",
        "    \"Deep learning is awesome\",\n",
        "    \"Natural language processing is interesting\"\n",
        "]"
      ],
      "metadata": {
        "id": "q4ljaxWNHnyi"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute tf-idf scores\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "glq4PIScH0it"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get top words based on tf-idf\n",
        "importance_threshold = 0.2\n",
        "important_words = [\n",
        "    feature_names[idx] for idx, score in enumerate(tfidf_matrix.toarray()[0]) if score > importance_threshold\n",
        "]"
      ],
      "metadata": {
        "id": "h3t-Jj69IK0I"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Important words for training: \", important_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvJe0x3PIfjw",
        "outputId": "61c22523-b50b-45eb-af4d-632e604a55cd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Important words for training:  ['amazing', 'is', 'learning', 'machine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding"
      ],
      "metadata": {
        "id": "T3Msp-N9I2xC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ysl4jZOiImqw"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize random embedding\n",
        "embedding_size = 9\n",
        "vocab = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
        "embedding_dict = {word: np.random.rand(embedding_size) for word in vocab}"
      ],
      "metadata": {
        "id": "cP0QPL5GKSuO"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print embeddings for each word\n",
        "for word, embedding in embedding_dict.items():\n",
        "  print(f\"{word}: {embedding}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7UEimm1Kjnt",
        "outputId": "1d8cea4e-cab9-4cf4-dcf1-d1c19185b9f3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: [0.29649993 0.06894139 0.64594602 0.2261799  0.34018184 0.37321896\n",
            " 0.02797216 0.6193868  0.45396172]\n",
            "quick: [6.40223200e-01 1.60633294e-01 5.31612529e-01 8.98870236e-01\n",
            " 9.97338341e-01 5.74264070e-01 2.89786510e-01 2.67043774e-01\n",
            " 8.84860827e-04]\n",
            "brown: [0.79381324 0.43095386 0.95665607 0.5780545  0.59604417 0.03567627\n",
            " 0.02466823 0.93072177 0.04986714]\n",
            "fox: [0.31388851 0.30469892 0.09565952 0.66766076 0.91579526 0.85856697\n",
            " 0.32946515 0.59259439 0.82616203]\n",
            "jumps: [0.85945934 0.03656065 0.12017924 0.44196285 0.50546647 0.27802044\n",
            " 0.04518222 0.16086026 0.37015752]\n",
            "over: [0.95955083 0.55091684 0.56349494 0.16655973 0.5753885  0.55467389\n",
            " 0.15906548 0.53726099 0.55166269]\n",
            "lazy: [0.57359462 0.54968877 0.63229307 0.90689625 0.20123622 0.40803974\n",
            " 0.99954071 0.44123054 0.63231006]\n",
            "dog: [0.13622454 0.85477554 0.02056476 0.56636478 0.13533947 0.03022967\n",
            " 0.48237713 0.69857204 0.63903754]\n"
          ]
        }
      ]
    }
  ]
}