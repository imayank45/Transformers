{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAndmeG__oGd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers peft datasets accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR5RA1le_xqv",
        "outputId": "67eb7c08-4902-4880-e415-8ac731216c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All libraries verified, installed and imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Verify installations\n",
        "try:\n",
        "    import transformers\n",
        "    import peft\n",
        "    import datasets\n",
        "    import accelerate\n",
        "    print(\"All libraries verified, installed and imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMlkvM3vAPE8",
        "outputId": "7b8b810a-0b8d-4b5a-a806-d61686d13079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported succssfully\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "  from datasets import load_dataset\n",
        "  from transformers import TrainingArguments, Trainer\n",
        "  print('Libraries imported succssfully')\n",
        "except ImportError as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl37QhaPBcnT",
        "outputId": "50796838-e8d3-4d99-84ab-99470d812bf0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# load the model\n",
        "try:\n",
        "  model = 'distilgpt2'\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model)\n",
        "  print('Model loaded successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujbt5LW3B9zd",
        "outputId": "74c3f238-1cda-4b9c-e239-dc645c8c2cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt: India\n",
            "Prompt entered successfully\n"
          ]
        }
      ],
      "source": [
        "# input prompt\n",
        "try:\n",
        "  prompt = input('Enter your prompt: ')\n",
        "  print('Prompt entered successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HCLhL4mLST9",
        "outputId": "ff5f817e-14b6-47d1-e175-23e4e1594597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input tokenized successfully\n"
          ]
        }
      ],
      "source": [
        "# tokenize the input\n",
        "try:\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "  print('Input tokenized successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba5xy55VLu-U",
        "outputId": "d4c68f93-7b27-46c8-aadb-c857b86e58c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "India The Indian government has announced that it will launch a new initiative to combat terrorism in the country.\n",
            "\n",
            "The initiative will be launched in a bid to tackle terrorism, the Indian Ministry of External Affairs said in its official statement. The initiative is aimed at combating terrorism and will also be aimed towards combating the spread of terrorism. It will target the most common terrorist groups, including the Taliban, Lashkar-e-Taiba, and the Lashkhar-i-Shia militant group.\n",
            "Text generated successfully\n"
          ]
        }
      ],
      "source": [
        "# generate the required text\n",
        "try:\n",
        "  output = model.generate(input_ids, max_length=500, num_return_sequences=1, no_repeat_ngram_size=2)\n",
        "  decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "  print(decoded_output)\n",
        "  print('Text generated successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqReh20-ZFHC"
      },
      "source": [
        "# Fine Tunning of Transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAiMq3GpPAUY",
        "outputId": "e26987b7-4724-4d68-b282-433773451c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "try:\n",
        "  dataset = datasets.load_dataset('json', data_files='/content/programming_jokes.json')\n",
        "  print('Dataset loaded successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woSDCqd2T6Td",
        "outputId": "b18814fb-c2e3-4c00-d09d-fb86e73d386f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LUAK_USZ6Wd",
        "outputId": "fddb6c76-53ad-4d8e-f90e-e3ca2d1be3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'Why do programmers prefer dark mode? Because light attracts bugs!'}\n",
            "{'text': 'Why do programmers hate nature? It has too many bugs.'}\n",
            "{'text': 'Why was the programmer always calm? Because they had a good cache.'}\n",
            "{'text': 'Why did the programmer go broke? They lost their domain in a bidding war.'}\n",
            "{'text': \"Why do Java developers wear glasses? Because they can't C#.\"}\n",
            "{'text': 'Why was the function sad? It didn’t get any arguments.'}\n",
            "{'text': 'Why did the programmer quit their job? They didn’t get arrays.'}\n",
            "{'text': 'Why do programmers love coffee? Because it keeps them from being in sleep mode.'}\n",
            "{'text': 'What’s a programmer’s favorite type of music? Algorithms and blues.'}\n",
            "{'text': 'Why did the programmer get stuck in the shower? The instructions said: lather, rinse, repeat.'}\n",
            "\n",
            "Jokes printed successfully\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  for i in range(10):\n",
        "    print(dataset['train'][i])\n",
        "  print('\\nJokes printed successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPNpB8koiIaP",
        "outputId": "9ceb607c-0aaf-4474-b3dc-eebeebf2d8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer padded successfully\n"
          ]
        }
      ],
      "source": [
        "# Ensure the tokenizer has a padding\n",
        "try:\n",
        "  if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "  print('Tokenizer padded successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18dhwur0eSKV",
        "outputId": "08d46298-ba0a-4c6c-c1fc-57e1d8a0b29f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer function defined successfully\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  def tokenizer_function(examples):\n",
        "    inputs = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "    inputs['labels'] = inputs['input_ids'].copy()\n",
        "    return inputs\n",
        "  print('Tokenizer function defined successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLmQGf4aL8p",
        "outputId": "6c731a26-3cfa-4346-bbcd-bf2d051dfc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized dataset created successfully\n"
          ]
        }
      ],
      "source": [
        "# tokenized dataset\n",
        "try:\n",
        "  tokenized_dataset = dataset.map(tokenizer_function, batched=True)\n",
        "  print('Tokenized dataset created successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ritob5F0eLAT",
        "outputId": "eebdec26-4521-420e-eceb-6f33510464e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainer created successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-22-eb276dc3f3ce>:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  training_args = TrainingArguments(\n",
        "      output_dir='./results',\n",
        "      num_train_epochs=2,\n",
        "      per_device_train_batch_size=50,\n",
        "      save_steps=10,\n",
        "      save_total_limit=2,\n",
        "      logging_dir='./logs',\n",
        "      logging_steps=10\n",
        "  )\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=tokenized_dataset['train'],\n",
        "      tokenizer=tokenizer\n",
        "  )\n",
        "  print('Trainer created successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvRqY1_aPfi4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Disable wandb logs\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "FFhPq0_5N2wj",
        "outputId": "63ceaec9-8c25-41b7-ea31-fad2a223175a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [40/40 01:13, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.050100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.030900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.026800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.027100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained successfully\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "try:\n",
        "  trainer.train()\n",
        "  print('Model trained successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDorH_q_OFA3",
        "outputId": "d1f5f666-9b99-468a-f51d-421e0f138b5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./fine_tuned_model/tokenizer_config.json',\n",
              " './fine_tuned_model/special_tokens_map.json',\n",
              " './fine_tuned_model/vocab.json',\n",
              " './fine_tuned_model/merges.txt',\n",
              " './fine_tuned_model/added_tokens.json',\n",
              " './fine_tuned_model/tokenizer.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('./fine_tuned_model')\n",
        "tokenizer.save_pretrained('./fine_tuned_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEZvsasbayGd",
        "outputId": "9a32516a-a113-4ae7-adb7-6b1068d3f983"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/fine_tuned_model/ (stored 0%)\n",
            "  adding: content/fine_tuned_model/config.json (deflated 51%)\n",
            "  adding: content/fine_tuned_model/tokenizer_config.json (deflated 54%)\n",
            "  adding: content/fine_tuned_model/model.safetensors (deflated 7%)\n",
            "  adding: content/fine_tuned_model/merges.txt (deflated 53%)\n",
            "  adding: content/fine_tuned_model/vocab.json (deflated 59%)\n",
            "  adding: content/fine_tuned_model/generation_config.json (deflated 24%)\n",
            "  adding: content/fine_tuned_model/special_tokens_map.json (deflated 60%)\n",
            "  adding: content/fine_tuned_model/tokenizer.json (deflated 82%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/fine_tuned_model.zip /content/fine_tuned_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxRjM6oscrr6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZsBHyAdsbLqY",
        "outputId": "554bf31d-1c62-482d-efec-4c2b22a0d466"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9b6fe3a0-d96d-4945-9b7d-40f1d60d7934\", \"fine_tuned_model.zip\", 305593929)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/fine_tuned_model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZKQoqB7bdTh",
        "outputId": "a1ee37d1-34e1-4bde-b882-98848e33d342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model extracted to /content/fine_tuned_model\n",
            "Model loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the .zip file\n",
        "zip_path = \"/content/fine_tuned_model.zip\"\n",
        "extracted_path = \"/content/fine_tuned_model\"\n",
        "\n",
        "# Extract the .zip file\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "    print(f\"Model extracted to {extracted_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting the zip file: {e}\")\n",
        "\n",
        "# Load the model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(extracted_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(extracted_path)\n",
        "    print(\"Model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input prompt\n",
        "try:\n",
        "  prompt = input('Enter your prompt: ')\n",
        "  print('Prompt entered successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo5pTQGggyDs",
        "outputId": "106a88a5-a6bb-44ab-d08e-fb4d1cffe0da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: Hello\n",
            "Prompt entered successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the input\n",
        "try:\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "  print('Input tokenized successfully')\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5SvHe8tg4OU",
        "outputId": "6c95e5a1-fd31-4a83-c632-955f47acd8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokenized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    input_ids,\n",
        "    max_length=50,\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=50,\n",
        "    do_sample=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0noCbBfefmy",
        "outputId": "e0013104-5b17-45b4-e2b7-9954773d457d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fei6OFDfaQu",
        "outputId": "992698a9-e8b7-483a-f0f8-7b2f5c527428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello do programmers love coffee? Because it keeps them from being in sleep mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvRJgiEZfnXE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}